{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Week10_RNN_210426.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"93lS-AmcovBt"},"source":["# 1. RNN"]},{"cell_type":"markdown","metadata":{"id":"2Qbo7PtNCsN1"},"source":["To understand RNN, one should know some data are sequential  \n","Sequential data is literally data in sequence, that is, the order of matters\n","\n","For non-sequential data types, e.g. sets, the below would be true\n","```python\n","{1, 2, 3} == {1, 3, 2}\n","```\n","But for sequential data:\n","```python\n","[1, 2, 3] != [1, 3, 2]\n","```\n","__Time series__ is a type of sequential data, which data points are recorded successively over a time period"]},{"cell_type":"markdown","metadata":{"id":"w-ZkRU1FIg3m"},"source":["## RNN Basics"]},{"cell_type":"code","metadata":{"id":"-zAXWDPjGbSH"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJ9fX49AGePa"},"source":["seq = torch.arange(1., 16.)\n","\n","print(type(seq))\n","print(seq)\n","print(seq.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eefgQktAGz2O"},"source":["# Number of previous data points to be taken in account\n","seq_length = 5\n","batch_size = len(seq) // seq_length\n","# Number of features\n","input_size = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l3sJbZxoHrRG"},"source":["X = seq.view(batch_size, seq_length, input_size)\n","\n","print(X.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FQzDaXGAv56"},"source":["import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Vz1nvkj26Ds"},"source":["# Number of features in hidden state\n","hidden_size = 10\n","# Number of RNN layers stacked\n","num_layers = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Amn5lfCp26FN"},"source":["singleRNN = nn.RNN(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    nonlinearity='tanh',\n","    batch_first=True,\n","    dropout=0,\n","    bidirectional=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKER6Nvu26Ft"},"source":["y, h = singleRNN(X)\n","\n","print(y.size())    # (batch_size, seq_length, hidden_size * num_directions)\n","print(h.size())    # (num_layers * num_directions, batch_size, hidden_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iF3--inA26Hi"},"source":["## Image Classification with RNN"]},{"cell_type":"code","metadata":{"id":"A0soapA-26Hj"},"source":["import torchvision\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0QHbjiO26Hm"},"source":["transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n","testset = torchvision.datasets.MNIST(root='./mnist', train=False, transform=transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3kTyice26Ht"},"source":["batch_size = 1000\n","num_workers = 0\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgDPOcWl26Hy"},"source":["class ImageRNN(nn.Module):\n","    def __init__(self, batch_size, seq_length, input_size, hidden_size, num_layers, num_classes):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.seq_length = seq_length\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.num_classes = num_classes\n","        \n","        self.rnn = nn.RNN(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n","        self.fc = nn.Linear(self.hidden_size * self.seq_length, self.num_classes)\n","\n","    def forward(self, x, h0):\n","        x = x.view(-1, 28, 28)    # (batch_size, channel, width, height) --> (batch_size, width as seq_length, height * channel as feature)\n","        out, _ = self.rnn(x, h0)    # (batch_size, seq_length, num_directions * hidden_size)\n","        out = out.reshape(-1, (self.seq_length * self.hidden_size))    # (batch, seq_length * num_directions * hidden_size)\n","        outputs = self.fc(out)    # (batch_size, num_classes)\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zE_rI6qP26H-"},"source":["import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWtbv9G626H1"},"source":["seq_length = 28\n","input_size = 28\n","hidden_size = 50\n","num_layers = 1\n","num_classes = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4LfTgXz26H6"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"96S9txVi26IB"},"source":["model = ImageRNN(batch_size, seq_length, input_size, hidden_size, num_layers, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDSAGZYc26IE"},"source":["epochs = 10\n","\n","model.train()\n","for epoch in range(epochs):\n","    train_loss = 0\n","    train_correct = 0\n","\n","    for x, y in trainloader:\n","        x, y = x.to(device), y.to(device)\n","        h0 = torch.zeros(num_layers, batch_size, hidden_size).to(device)    # (num_layers * num_directions, batch_size, hidden_size)\n","\n","        optimizer.zero_grad()\n","        outputs = model(x, h0)\n","        loss = criterion(outputs, y)\n","                \n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        train_correct += predicted.eq(y).sum().item()\n","        \n","    train_loss = train_loss / len(trainloader)\n","    train_acc = train_correct / len(trainset)\n","        \n","    print('[%2d] TRAIN loss: %.4f, acc: %.4f' % (epoch + 1, train_loss, train_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGKQPHat26II"},"source":["test_loss = 0\n","test_correct = 0\n","test_preds = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for x, y in testloader:\n","        x, y = x.to(device), y.to(device)\n","        h0 = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n","\n","        outputs = model(x, h0)\n","        loss = criterion(outputs, y)\n","        \n","        test_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        test_correct += predicted.eq(y).sum().item()\n","        \n","        test_preds.extend(predicted.tolist())\n","        \n","print('TEST loss: %.4f, acc: %.4f' % (test_loss/len(testloader), test_correct/len(testset)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQIKPhYh26F_"},"source":["## Stacked RNN"]},{"cell_type":"code","metadata":{"id":"ayOei0N8ktrl"},"source":["batch_size = 3\n","input_size = 1\n","seq_length = 5\n","hidden_size = 10\n","num_layers = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvQkg6jH26GA"},"source":["stackedRNN = nn.RNN(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    batch_first=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZT6MshC26GF"},"source":["X = seq.view(batch_size, seq_length, input_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqeuc6JX26GL"},"source":["y, h_n = stackedRNN(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehdd-Afm26GQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"okFOis2X26Gb"},"source":["## Bi-directional RNN"]},{"cell_type":"code","metadata":{"id":"oetb606626Gc"},"source":["biRNN = nn.RNN(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    batch_first=True,\n","    bidirectional=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkwe0y4vU7tH"},"source":["y, h_n = biRNN(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4g3hYAsU26Gu"},"source":["print(y.size())    # (batch_size, seq_length, hidden_size * num_directions)\n","print(h_n.size())    # (num_layers * num_directions, batch_size, hidden_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76NejugL26G3"},"source":["y_bi = y.view(batch_size, seq_length, 2, hidden_size)\n","\n","print(y_bi.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGxdE5LD26HB"},"source":["y_forward = y_bi[:,:,0,:]\n","y_backward = y_bi[:,:,1,:]\n","\n","print(y_forward.size())\n","print(y_backward.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I2uH75ha26HM"},"source":["h_n_bi = h_n.view(num_layers, 2, batch_size, hidden_size)\n","\n","print(h_n_bi.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTrAhJbl26HS"},"source":["h_n_forward = h_n_bi[:,:,0,:]\n","h_n_backward = h_n_bi[:,:,1,:]\n","\n","print(h_n_forward.size())\n","print(h_n_backward.size())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TRgaV-co4AW3"},"source":["## LSTM\n"]},{"cell_type":"code","metadata":{"id":"RC8TVAa527x-"},"source":["lstm = nn.LSTM(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    batch_first=True,\n","    dropout=0,\n","    bidirectional=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YXg6KSV27yL"},"source":["y, h_n = lstm(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1CE5aQM27yV"},"source":["print(y.size())    # (batch_size, seq_length, hidden_size * num_directions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZ9j8h6nWuMo"},"source":["## Character Prediction with RNN"]},{"cell_type":"code","metadata":{"id":"30E90kVHWt0K"},"source":["char_set = ['d', 'e', 'h', 'l', 'o', 'r', 'w', ' ']\n","\n","input_size = len(char_set)\n","hidden_size = 16\n","output_size = len(char_set)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Von6_jBdXA9s"},"source":["x = [[2, 1, 3, 3, 4, 7, 6, 4, 5, 3]] # hello worl\n","x_onehot = [[[0, 0, 1, 0, 0, 0, 0, 0],  # h\n","             [0, 1, 0, 0, 0, 0, 0, 0],  # e\n","             [0, 0, 0, 1, 0, 0, 0, 0],  # l\n","             [0, 0, 0, 1, 0, 0, 0, 0],  # l\n","             [0, 0, 0, 0, 1, 0, 0, 0],  # o\n","             [0, 0, 0, 0, 0, 0, 0, 1],  #\n","             [0, 0, 0, 0, 0, 0, 1, 0],  # w\n","             [0, 0, 0, 0, 1, 0, 0, 0],  # o\n","             [0, 0, 0, 0, 0, 1, 0, 0],  # r\n","             [0, 0, 0, 1, 0, 0, 0, 0]]]\n","\n","y = [[1, 3, 3, 4, 7, 6, 4, 5, 3, 0]] # ello world\n","\n","X = torch.FloatTensor(x_onehot)\n","Y = torch.LongTensor(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5n-HlblZNzs"},"source":["class simpleRNN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.rnn = torch.nn.RNN(input_dim, hidden_dim, batch_first=True)\n","        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x, _status = self.rnn(x)\n","        x = self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IW6PbyPZVnM"},"source":["model = simpleRNN(input_size, hidden_size, output_size)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghTwhXsAbWbn"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGUyWnOCZcGZ"},"source":["epochs = 5\n","\n","model.train()\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X)\n","    loss = criterion(outputs.view(-1, input_size), Y.view(-1))\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    predicted = outputs.data.numpy().argmax(axis=2)\n","    prediction = ''.join([char_set[c] for c in np.squeeze(predicted)])\n","    print('[%2d] TRAIN loss: %.4f, pred: %s' % (epoch + 1, loss.item(), prediction))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zMiOnSndfz5Y"},"source":["## Gender Classficiation with RNN"]},{"cell_type":"code","metadata":{"id":"0pGuELEFf5xN"},"source":["char_set = ['a', 'd', 'e', 'h', 'i', 'n', 'o', 'p', 'r', 's', 'w']\n","input_size = len(char_set)\n","hidden_size = 22\n","output_size = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BV70n2T1f5oG"},"source":["x = [[0, 5, 1, 8, 2, 10], # andrew,\n","     [9, 6, 7, 3, 4, 0]]  # sophia\n","\n","x_onehot = [[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # a\n","             [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # n\n","             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # d\n","             [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # r\n","             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # e\n","             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], # w\n","            \n","            [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],  # s\n","             [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],  # o\n","             [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],  # p\n","             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # h\n","             [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # i\n","             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] # a\n","\n","y = [[0],  # Male\n","     [1]]  # Female\n","\n","X = torch.FloatTensor(x_onehot)\n","Y = torch.FloatTensor(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BL9nF4gPgeON"},"source":["class simpleRNN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super().__init__()\n","        self.rnn = torch.nn.RNN(input_dim, hidden_dim, batch_first=True)\n","        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x, _status = self.rnn(x)\n","        x = self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NXvTTjzggpD"},"source":["model = simpleRNN(input_size, hidden_size, output_size)\n","criterion = torch.nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCoiS3tcgkl0"},"source":["epochs = 20\n","\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X)\n","    loss = criterion(outputs[:, -1, :].squeeze(), Y.view(-1))\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    predicted = [\"Male\" if x < 0.5 else \"Female\" for x in outputs[:, -1, :].squeeze().tolist()]\n","    print('[%2d] TRAIN loss: %.4f, pred: %s' % (epoch + 1, loss.item(), predicted))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_CHVNr36cFOn"},"source":["## Seq2Seq"]},{"cell_type":"code","metadata":{"id":"jOBCmLOQAIcF"},"source":["raw = [\"I feel hungry.\t나는 배가 고프다.\",\n","       \"Pytorch is very easy.\t파이토치는 매우 쉽다.\",\n","       \"Pytorch is a framework for deep learning.\t파이토치는 딥러닝을 위한 프레임워크이다.\",\n","       \"Pytorch is very clear to use.\t파이토치는 사용하기 매우 직관적이다.\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JuazViVlAIcH"},"source":["# Fix token for \"start of sentence\" and \"end of sentence\"\n","SOS_token = 0\n","EOS_token = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3avydpwOAIcK"},"source":["# Class for vocabulary related information of data\n","class Vocab:\n","    def __init__(self):\n","        self.vocab2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token}\n","        self.index2vocab = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n","        self.vocab_count = {}\n","        self.n_vocab = len(self.vocab2index)\n","\n","    def add_vocab(self, sentence):\n","        for word in sentence.split(\" \"):\n","            if word not in self.vocab2index:\n","                self.vocab2index[word] = self.n_vocab\n","                self.vocab_count[word] = 1\n","                self.index2vocab[self.n_vocab] = word\n","                self.n_vocab += 1\n","            else:\n","                self.vocab_count[word] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eb6GpKghAIcL"},"source":["# Filter out the long sentence from source and target data\n","def filter_pair(pair, source_max_length, target_max_length):\n","    return len(pair[0].split(\" \")) < source_max_length and len(pair[1].split(\" \")) < target_max_length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEP0b077AIcO"},"source":["# Read and preprocess the corpus data\n","def preprocess(corpus, source_max_length, target_max_length):\n","    print(\"...Reading corpus...\")\n","    pairs = []\n","    for line in corpus:\n","        pairs.append([s for s in line.strip().lower().split(\"\\t\")])\n","    print(\"Read {} sentence pairs\".format(len(pairs)))\n","\n","    pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]\n","    print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n","\n","    source_vocab = Vocab()\n","    target_vocab = Vocab()\n","\n","    print(\"...Counting words...\")\n","    for pair in pairs:\n","        source_vocab.add_vocab(pair[0])\n","        target_vocab.add_vocab(pair[1])\n","    print(\"source vocab size =\", source_vocab.n_vocab)\n","    print(\"target vocab size =\", target_vocab.n_vocab)\n","\n","    return pairs, source_vocab, target_vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lozRyCsuAIcQ"},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        return x, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTgf-C2xAIcS"},"source":["class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        x = self.softmax(self.out(x[0]))\n","        return x, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YOUpmMiAIcU"},"source":["# Convert sentence to the index tensor\n","def tensorize(vocab, sentence):\n","    indexes = [vocab.vocab2index[word] for word in sentence.split(\" \")]\n","    indexes.append(vocab.vocab2index[\"<EOS>\"])\n","    return torch.Tensor(indexes).long().to(device).view(-1, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_e7APioRAIcW"},"source":["# Training seq2seq\n","def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every=1000, learning_rate=0.01):\n","    loss_total = 0\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    training_batch = [random.choice(pairs) for _ in range(n_iter)]\n","    training_source = [tensorize(source_vocab, pair[0]) for pair in training_batch]\n","    training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n","\n","    criterion = nn.NLLLoss()\n","\n","    for i in range(1, n_iter + 1):\n","        source_tensor = training_source[i - 1]\n","        target_tensor = training_target[i - 1]\n","\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","\n","        source_length = source_tensor.size(0)\n","        target_length = target_tensor.size(0)\n","\n","        loss = 0\n","\n","        for enc_input in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n","\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden # connect encoder output to decoder input\n","\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # teacher forcing\n","\n","        loss.backward()\n","\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","        loss_iter = loss.item() / target_length\n","        loss_total += loss_iter\n","\n","        if i % print_every == 0:\n","            loss_avg = loss_total / print_every\n","            loss_total = 0\n","            print(\"[{} - {}%] loss = {:05.4f}\".format(i, i / n_iter * 100, loss_avg))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHv2pjjAAIcY"},"source":["# Insert given sentence to check the training\n","def evaluate(pairs, source_vocab, target_vocab, encoder, decoder, target_max_length):\n","    for pair in pairs:\n","        print(\">\", pair[0])\n","        print(\"=\", pair[1])\n","        source_tensor = tensorize(source_vocab, pair[0])\n","        source_length = source_tensor.size()[0]\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        for ei in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[ei], encoder_hidden)\n","\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden\n","        decoded_words = []\n","\n","        for di in range(target_max_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            _, top_index = decoder_output.data.topk(1)\n","            if top_index.item() == EOS_token:\n","                decoded_words.append(\"<EOS>\")\n","                break\n","            else:\n","                decoded_words.append(target_vocab.index2vocab[top_index.item()])\n","\n","            decoder_input = top_index.squeeze().detach()\n","\n","        predict_words = decoded_words\n","        predict_sentence = \" \".join(predict_words)\n","        print(\"<\", predict_sentence)\n","        print(\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bOwXZoSAIca"},"source":["# Declare max length for sentence\n","SOURCE_MAX_LENGTH = 10\n","TARGET_MAX_LENGTH = 12"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4MnnXatca03"},"source":["import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7s3oSsr2AIcb"},"source":["# Preprocess the corpus\n","load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH, TARGET_MAX_LENGTH)\n","print(random.choice(load_pairs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljuiyexwAIce"},"source":["# Declare the encoder and the decoder\n","enc_hidden_size = 16\n","dec_hidden_size = enc_hidden_size\n","enc = Encoder(load_source_vocab.n_vocab, enc_hidden_size).to(device)\n","dec = Decoder(dec_hidden_size, load_target_vocab.n_vocab).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCbq5Ai9AIcg"},"source":["# Train seq2seq model\n","train(load_pairs, load_source_vocab, load_target_vocab, enc, dec, 5000, print_every=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpDC9YbxAIci"},"source":["# Check the model with given data\n","evaluate(load_pairs, load_source_vocab, load_target_vocab, enc, dec, TARGET_MAX_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zX9PUGAiZ09t"},"source":[""],"execution_count":null,"outputs":[]}]}